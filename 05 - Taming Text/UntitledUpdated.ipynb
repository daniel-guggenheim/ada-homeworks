{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergii\\Anaconda3\\lib\\site-packages\\gensim-0.13.3-py3.5-win-amd64.egg\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Sergii\\Anaconda3\\lib\\site-packages\\gensim-0.13.3-py3.5-win-amd64.egg\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords, stemming and tokenizing\n",
    "#### 1. load list of English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "english_vocab = set(w.lower() for w in nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extend set of stopwords modals with modal verbs\n",
    "stopwords = stopwords + ['could', 'may', 'might', 'must', 'ought to', 'shall', 'would']\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-03T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber                                    MetadataSubject  \\\n",
       "0   1  C05739545                                                WOW   \n",
       "1   2  C05739546  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "\n",
       "  MetadataTo       MetadataFrom  SenderPersonId           MetadataDateSent  \\\n",
       "0          H  Sullivan, Jacob J            87.0  2012-09-12T04:00:00+00:00   \n",
       "1          H                NaN             NaN  2011-03-03T05:00:00+00:00   \n",
       "\n",
       "        MetadataDateReleased  \\\n",
       "0  2015-05-22T04:00:00+00:00   \n",
       "1  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "1  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "1                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>         NaN   \n",
       "1                                       NaN         NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "1                                     NaN        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "1          C05739546            05/13/2015              RELEASE IN PART   \n",
       "\n",
       "                                   ExtractedBodyText  \\\n",
       "0                                                NaN   \n",
       "1  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "1  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_file = os.path.join('hillary-clinton-emails', 'Emails.csv')\n",
    "emails_df = pd.read_csv(emails_file)\n",
    "emails_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataDocumentClass</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOW</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>FW: Wow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MetadataSubject MetadataDocumentClass  \\\n",
       "0                                                WOW         HRC_Email_296   \n",
       "1  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...         HRC_Email_296   \n",
       "\n",
       "  ExtractedSubject                                  ExtractedBodyText  \\\n",
       "0          FW: Wow                                                NaN   \n",
       "1              NaN  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "1  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling_df = emails_df.copy()\n",
    "topic_modeling_df.drop(['Id'\n",
    "                        , 'DocNumber'\n",
    "                        , 'MetadataTo'\n",
    "                        , 'MetadataFrom'\n",
    "                        , 'SenderPersonId'\n",
    "                        , 'MetadataDateSent'\n",
    "                        , 'MetadataDateReleased'\n",
    "                        , 'MetadataPdfLink'\n",
    "                        , 'MetadataCaseNumber'\n",
    "                        , 'ExtractedTo'\n",
    "                        , 'ExtractedFrom'\n",
    "                        , 'ExtractedCc'\n",
    "                        , 'ExtractedDateSent'\n",
    "                        , 'ExtractedCaseNumber'\n",
    "                        , 'ExtractedDocNumber'\n",
    "                        , 'ExtractedDateReleased'\n",
    "                        , 'ExtractedReleaseInPartOrFull'], axis=1, inplace=True)\n",
    "topic_modeling_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_modeling_df = topic_modeling_df.dropna(subset=['ExtractedBodyText'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataDocumentClass</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MetadataSubject MetadataDocumentClass  \\\n",
       "1  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...         HRC_Email_296   \n",
       "2                                      CHRIS STEVENS         HRC_Email_296   \n",
       "\n",
       "    ExtractedSubject                                  ExtractedBodyText  \\\n",
       "1                NaN  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "2  Re: Chris Stevens                                                Thx   \n",
       "\n",
       "                                             RawText  \n",
       "1  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  \n",
       "2  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def re_longer_than(N):\n",
    "    return re.compile('^[a-z]{' + '{0},'.format(N) + '}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_word_filter = re_longer_than(4)\n",
    "\n",
    "def preprocess_msg(msg):\n",
    "    sentences = nltk.sent_tokenize(msg)\n",
    "    del sentences[:6]\n",
    "    del sentences[-7:]\n",
    "    \n",
    "    tokens = []\n",
    "    for s in sentences:\n",
    "        curr_tokens = nltk.word_tokenize(s)\n",
    "        curr_tokens = [word for word in curr_tokens if word in english_vocab]\n",
    "        curr_tokens = [word for word in curr_tokens if word not in stopwords]\n",
    "        curr_tokens = list(filter(lambda x: re_word_filter.match(x) ,curr_tokens))\n",
    "        tokens = tokens + curr_tokens\n",
    "\n",
    "    return tokens    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Porter Stemmer which is actually part of NLTK. We should do **stemming** - breaking a word down into its root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "curr_stem_map = {}\n",
    "\n",
    "def cleanup_stem(): curr_stem_map.clear()\n",
    "\n",
    "def bind_stem(token):\n",
    "    t_stem = p_stemmer.stem(token)\n",
    "    s = curr_stem_map.get(t_stem, set())\n",
    "    if not s:\n",
    "        curr_stem_map[t_stem] = s\n",
    "        curr_stem_map[t_stem].add(token)\n",
    "    return t_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def steamming(tokens_per_msg):\n",
    "    return [[bind_stem(t) for t in tokens] for tokens in tokens_per_msg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to generate an LDA model, we need to understand how frequently each term occurs within each document;\n",
    "# to do that, we need to construct a document-term matrix\n",
    "\n",
    "def calculate_topics(message_group):\n",
    "    tokens_per_msg = [preprocess_msg(msg) for msg in message_group]\n",
    "    tokens_per_msg = steamming(tokens_per_msg)\n",
    "    \n",
    "    # the Dictionary() function traverses texts, assigning a unique integer id to each unique token \n",
    "    # while also collecting word counts and relevant statistics. \n",
    "    dictionary = corpora.Dictionary(tokens_per_msg)\n",
    "    \n",
    "    if not bool(dictionary):\n",
    "        return None\n",
    "    \n",
    "    # The doc2bow() function converts dictionary into a bag-of-words.\n",
    "    # The result, corpus, is a list of vectors equal to the number of documents;\n",
    "    # in each document vector is a series of tuples\n",
    "    # The tuples are (term ID, term frequency) pairs. doc2bow() only includes terms \n",
    "    # that actually occur: terms that do not occur in a document will not \n",
    "    # appear in that document’s vector.\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_per_msg]\n",
    "    N = 5 if len(message_group) == 1 else 25\n",
    "\n",
    "    # Applying the LDA model\n",
    "    ldamodel = models.ldamodel.LdaModel(corpus, num_topics=25, id2word = dictionary, passes=N)\n",
    "\n",
    "    # topics_matrix\n",
    "    return ldamodel.show_topics(formatted=False, num_words=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataDocumentClass</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "      <th>MsgTopics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MetadataSubject MetadataDocumentClass  \\\n",
       "1  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...         HRC_Email_296   \n",
       "\n",
       "  ExtractedSubject                                  ExtractedBodyText  \\\n",
       "1              NaN  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "\n",
       "                                             RawText MsgTopics  \n",
       "1  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...            "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdf_topic_by_group_df = topic_modeling_df.copy()\n",
    "tmdf_topic_by_group_df['MsgTopics'] = \"\"\n",
    "tmdf_topic_by_group_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_msgs_by_subject = tmdf_topic_by_group_df.groupby(['MetadataSubject'])\n",
    "gb = grouped_msgs_by_subject.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run calculation for every group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def destem_topics(topics_matrix):\n",
    "    if not topics_matrix:\n",
    "        return ''\n",
    "    \n",
    "    # we take first corresponding word from pre-mapped stem-words\n",
    "    return ' '.join([min(curr_stem_map[w]) for w, p in topics_matrix[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3315/3315 [15:37<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, indices in tqdm(gb.items(), ncols=len(gb)):\n",
    "    group = grouped_msgs_by_subject.get_group(key)\n",
    "    msg_dict = group['RawText'].to_dict()\n",
    "    topics_matrix = calculate_topics(list(msg_dict.values()))\n",
    "    \n",
    "    topics_str = destem_topics(topics_matrix)\n",
    "    cleanup_stem()\n",
    "    \n",
    "    for i in indices:\n",
    "        tmdf_topic_by_group_df.ix[i, 'MsgTopics'] = topics_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataDocumentClass</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "      <th>MsgTopics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "      <td>military zone support stated convinced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...</td>\n",
       "      <td>sorry surely morning front former</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>HRC_Email_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\r\\nFriday, March 1...</td>\n",
       "      <td>B6\\r\\nUNCLASSIFIED\\r\\nU.S. Department of State...</td>\n",
       "      <td>military zone support stated convinced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MetadataSubject MetadataDocumentClass  \\\n",
       "1  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...         HRC_Email_296   \n",
       "2                                      CHRIS STEVENS         HRC_Email_296   \n",
       "4  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...         HRC_Email_296   \n",
       "\n",
       "    ExtractedSubject                                  ExtractedBodyText  \\\n",
       "1                NaN  B6\\r\\nThursday, March 3, 2011 9:45 PM\\r\\nH: La...   \n",
       "2  Re: Chris Stevens                                                Thx   \n",
       "4                NaN  H <hrod17@clintonemail.com>\\r\\nFriday, March 1...   \n",
       "\n",
       "                                             RawText  \\\n",
       "1  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...   \n",
       "2  UNCLASSIFIED\\r\\nU.S. Department of State\\r\\nCa...   \n",
       "4  B6\\r\\nUNCLASSIFIED\\r\\nU.S. Department of State...   \n",
       "\n",
       "                                MsgTopics  \n",
       "1  military zone support stated convinced  \n",
       "2       sorry surely morning front former  \n",
       "4  military zone support stated convinced  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdf_topic_by_group_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = topic_modeling_df['RawText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_matrix = calculate_topics(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diplomacy military powerful public work\n"
     ]
    }
   ],
   "source": [
    "topics_str = destem_topics(topics_matrix)\n",
    "cleanup_stem()\n",
    "    \n",
    "print(topics_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(29, '0.138*\"per\" + 0.110*\"cent\" + 0.022*\"public\"'), (26, '0.034*\"election\" + 0.033*\"party\" + 0.028*\"would\"'), (17, '0.016*\"said\" + 0.014*\"reconstruction\" + 0.012*\"local\"'), (21, '0.014*\"military\" + 0.013*\"would\" + 0.011*\"former\"'), (23, '0.036*\"update\" + 0.025*\"family\" + 0.020*\"time\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(45,\n",
       "  '0.025*\"people\" + 0.024*\"get\" + 0.020*\"plan\" + 0.019*\"could\" + 0.018*\"kids\" + 0.018*\"school\" + 0.015*\"education\" + 0.014*\"work\" + 0.012*\"though\" + 0.011*\"help\"'),\n",
       " (40,\n",
       "  '0.044*\"percent\" + 0.022*\"said\" + 0.020*\"enough\" + 0.017*\"would\" + 0.015*\"need\" + 0.012*\"margin\" + 0.012*\"climate\" + 0.011*\"opinion\" + 0.010*\"help\" + 0.010*\"change\"'),\n",
       " (4,\n",
       "  '0.026*\"shall\" + 0.022*\"train\" + 0.020*\"nomination\" + 0.016*\"would\" + 0.016*\"turnout\" + 0.016*\"coup\" + 0.014*\"hold\" + 0.014*\"lift\" + 0.014*\"candidate\" + 0.014*\"recommend\"'),\n",
       " (19,\n",
       "  '0.027*\"staff\" + 0.021*\"president\" + 0.017*\"adviser\" + 0.017*\"former\" + 0.016*\"chief\" + 0.015*\"secretary\" + 0.015*\"earthquake\" + 0.014*\"year\" + 0.013*\"team\" + 0.011*\"campaign\"'),\n",
       " (37,\n",
       "  '0.017*\"new\" + 0.016*\"policy\" + 0.013*\"long\" + 0.012*\"video\" + 0.012*\"growth\" + 0.012*\"bank\" + 0.011*\"like\" + 0.011*\"society\" + 0.009*\"foreign\" + 0.009*\"ever\"'),\n",
       " (33,\n",
       "  '0.043*\"aid\" + 0.033*\"money\" + 0.026*\"government\" + 0.024*\"tax\" + 0.022*\"speech\" + 0.019*\"spending\" + 0.019*\"economy\" + 0.019*\"people\" + 0.015*\"pay\" + 0.014*\"water\"'),\n",
       " (9,\n",
       "  '0.009*\"people\" + 0.008*\"government\" + 0.008*\"one\" + 0.008*\"security\" + 0.007*\"would\" + 0.006*\"clear\" + 0.006*\"many\" + 0.006*\"team\" + 0.006*\"make\" + 0.005*\"world\"'),\n",
       " (12,\n",
       "  '0.030*\"said\" + 0.026*\"government\" + 0.023*\"people\" + 0.019*\"also\" + 0.012*\"minister\" + 0.012*\"poor\" + 0.011*\"get\" + 0.011*\"money\" + 0.011*\"used\" + 0.010*\"prime\"'),\n",
       " (8,\n",
       "  '0.040*\"delegation\" + 0.039*\"meeting\" + 0.023*\"newspaper\" + 0.023*\"discuss\" + 0.020*\"received\" + 0.020*\"message\" + 0.018*\"response\" + 0.016*\"plane\" + 0.012*\"routinely\" + 0.011*\"speaker\"'),\n",
       " (47,\n",
       "  '0.028*\"freedom\" + 0.016*\"valley\" + 0.016*\"history\" + 0.015*\"future\" + 0.013*\"open\" + 0.012*\"always\" + 0.011*\"world\" + 0.010*\"symbol\" + 0.010*\"end\" + 0.009*\"wall\"')]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=5, num_words=3))\n",
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movement', 'group', 'right', 'company', 'conservative', 'police', 'cable', 'white', 'front', 'oil', 'race', 'one', 'onto', 'death', 'hill', 'liberal', 'media', 'left', 'black', 'campaign'] \n",
      "\n",
      "['percent', 'would', 'religious', 'world', 'treaty', 'nation', 'new', 'faith', 'government', 'long', 'economic', 'like', 'growth', 'one', 'many', 'religion', 'debt', 'toward', 'face', 'political'] \n",
      "\n",
      "['deal', 'said', 'party', 'agreement', 'would', 'assembly', 'statement', 'last', 'new', 'peace', 'two', 'justice', 'vote', 'leader', 'see', 'support', 'press', 'community', 'government', 'minister'] \n",
      "\n",
      "['call', 'tomorrow', 'time', 'know', 'morning', 'today', 'back', 'update', 'office', 'like', 'route', 'speak', 'work', 'confirmed', 'schedule', 'talk', 'let', 'memo', 'available', 'need'] \n",
      "\n",
      "['administration', 'policy', 'nuclear', 'foreign', 'president', 'world', 'new', 'strategy', 'public', 'diplomacy', 'war', 'time', 'peace', 'would', 'state', 'official', 'even', 'one', 'settlement', 'senior'] \n",
      "\n",
      "['say', 'would', 'know', 'love', 'visit', 'line', 'security', 'like', 'participation', 'marriage', 'speak', 'message', 'even', 'meet', 'also', 'generally', 'spoke', 'old', 'pavilion', 'private'] \n",
      "\n",
      "['development', 'work', 'food', 'global', 'people', 'assistance', 'policy', 'new', 'health', 'local', 'world', 'training', 'education', 'gender', 'must', 'need', 'social', 'help', 'business', 'project'] \n",
      "\n",
      "['foreign', 'former', 'would', 'military', 'week', 'also', 'new', 'could', 'memo', 'think', 'say', 'get', 'war', 'said', 'inquiry', 'property', 'take', 'invasion', 'whether', 'secretary'] \n",
      "\n",
      "['security', 'political', 'important', 'former', 'may', 'country', 'also', 'report', 'public', 'situation', 'first', 'death', 'arrest', 'service', 'defense', 'paramilitary', 'local', 'across', 'work', 'support'] \n",
      "\n",
      "['meeting', 'team', 'draft', 'work', 'min', 'one', 'recognize', 'would', 'staff', 'going', 'meet', 'make', 'speech', 'time', 'get', 'per', 'hope', 'discussion', 'sure', 'great'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_matrix = ldamodel.show_topics(formatted=False, num_words=20)\n",
    "for i, words in topics_matrix:\n",
    "    print([w for w, p in words], '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
