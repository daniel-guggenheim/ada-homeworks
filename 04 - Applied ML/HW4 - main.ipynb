{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Homework 04 - Applied ML</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join('data','CrowdstormingDataJuly1st.csv') \n",
    "df = pd.read_csv(filename)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of dyads (rows in dataframe): ', len(df))\n",
    "print('Total number of interactions between a referee and a player (nb of games): ', sum(df.games))\n",
    "print('Mean number of games for a dyad: ', np.mean(df['games']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning / setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows in dataframe: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removing raters</b>: We decided to remove row where the two rates were significantly different or if any of the rates were absent (Nan value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleandf = df.copy()\n",
    "\n",
    "## Removing null values in raters\n",
    "cleandf = cleandf[cleandf[\"rater1\"].notnull() & cleandf[\"rater2\"].notnull()]\n",
    "\n",
    "## Removing all rows where the difference between the two raters is larger than 0.25\n",
    "cleandf['difference'] = abs(cleandf.rater1 - cleandf.rater2)\n",
    "cleandf = cleandf[cleandf['difference'] <= 0.25]\n",
    "cleandf.drop('difference', axis =1, inplace=True)\n",
    "\n",
    "print(\"Number of rows in the cleaned dataframe: \", len(cleandf))\n",
    "print(\"Number of rows removed: \", (len(df)-len(cleandf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Skin tone</b>: Then we decide to take the skin tone as the mean between the two raters. This is the value that will be predicted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleandf[\"meanSkinTone\"] = abs(cleandf[\"rater1\"] - cleandf[\"rater2\"] ) / 2\n",
    "# cols = cleandf.columns.tolist()\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "# cleandf = cleandf[cols]\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Birthday date</b>: As the classifier can not understand date, we decided to change birthday date in seconds. It seemed important for us to keep the birthday date, as it could help predict the color skin if there were more people from a certain demography that played during some years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def time_to_seconds(t):\n",
    "    seconds = (pd.to_datetime(t) - datetime.datetime(1970, 1,1)).total_seconds()\n",
    "    return int(seconds)\n",
    "\n",
    "cleandf.birthday = cleandf.birthday.apply(time_to_seconds)\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dummy variables</b>: We noticed that a lot of the columns could not be used in the Random forest as they are non-numerical. As most of these features can be seen as categorical variables, we decided to make dummy variables with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The number of different positions is\", cleandf[\"position\"].unique().size)\n",
    "print(\"The number of different clubs is\",cleandf[\"club\"].unique().size)\n",
    "print(\"The number of different league countries is\",cleandf[\"leagueCountry\"].unique().size)\n",
    "print(\"The number of different referee countries is\",cleandf[\"Alpha_3\"].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of these datas, we decided to remove the \"referee country\" (Alpha_3) and to make dummy variables with the 3 other categories. We decided to remove the referee country because there were a lot of them and it seemed it would induce more error and overfitting to our classifier than it would help it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummydf = pd.get_dummies(cleandf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"position\"], sparse=False, drop_first=False)\n",
    "dummydf = pd.get_dummies(dummydf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"club\"], sparse=False, drop_first=False)\n",
    "dummydf = pd.get_dummies(dummydf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"leagueCountry\"], sparse=False, drop_first=False)\n",
    "dummydf.drop(\"Alpha_3\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of columns in the previous dataframe: \",cleandf.columns.size)\n",
    "print(\"Number of columns in the new dataframe with dummy variables: \",dummydf.columns.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Replacing Nan</b>: We realize that the dataframe still have some NaN values. We decided to substitute every NaN with the mean of their column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummydf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each column, if there is any NaN value, we compute the mean and replace the NaN values with it.\n",
    "for i in range(len(dummydf.columns)):\n",
    "    if (dummydf[dummydf.columns[i]].isnull().values.any()):\n",
    "        mean = np.mean(dummydf[dummydf.columns[i]])\n",
    "        dummydf[dummydf.columns[i]].fillna(mean, inplace = True)\n",
    "        \n",
    "dummydf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removing useless columns</b>: For the classifier, there are some columns that it makes no sense to use. These columns are the player name (and short name), the photo and the initial ratings (of rater 1 and 2). Therefore we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usedf = dummydf.drop(['playerShort', 'player', 'photoID', 'rater1', 'rater2']  , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usedf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show how we classify the data using random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def executingRandomForest(X, y, Xpd):\n",
    "    # Creating kfolds\n",
    "    once = False\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    #Iterating for kfold validation\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "\n",
    "        ## Making indices\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #Make classifier\n",
    "        rf = RandomForestClassifier(n_jobs = 4)\n",
    "\n",
    "        #Train the classifier\n",
    "        clf = rf.fit(X_train, y_train)\n",
    "\n",
    "        # Make prediction for testing data with the classifier\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        #Computing error\n",
    "        rf_train_score = metrics.accuracy_score(y_train, clf.predict(X_train))\n",
    "        rf_test_score = metrics.accuracy_score(y_test, y_pred)\n",
    "        print('   Training score: {:.5f}'.format(rf_train_score))\n",
    "        print('   Testing score: {:.5f}'.format(rf_test_score))\n",
    "\n",
    "\n",
    "        # Features importance score\n",
    "        if(once != True):\n",
    "            once = True\n",
    "            importances = rf.feature_importances_\n",
    "            std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                         axis=0)\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "               color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), importances[indices])\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking (first 20):\")\n",
    "    for f in range(20):\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, Xpd.columns[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making X (the features to use in the classifier) and Y (the value to predict). Executing the random forest algorithm on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMatrixForClassifier(df):\n",
    "    y = np.asarray(df[\"meanSkinTone\"].values, dtype=\"|S6\")\n",
    "    Xpd = df.drop(\"meanSkinTone\", axis = 1)\n",
    "    X = Xpd.as_matrix()\n",
    "    return (X, y, Xpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X, y, Xpd) = makeMatrixForClassifier(usedf)\n",
    "executingRandomForest(X, y, Xpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that we overfit greatly. Ploting the features importance show...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notOverfittingMaybedf = usedf.drop(['birthday', 'height', 'weight']  , axis=1)\n",
    "(X, y, Xpd) = makeMatrixForClassifier(notOverfittingMaybedf)\n",
    "executingRandomForest(X, y, Xpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notOverfittingMaybedf = usedf.drop(['birthday', 'height', 'weight', 'games', 'victories', 'ties', 'defeats', 'goals']  , axis=1)\n",
    "(X, y, Xpd) = makeMatrixForClassifier(notOverfittingMaybedf)\n",
    "executingRandomForest(X, y, Xpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aggregate the referee info by socker player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "referee_info_df = dummydf.drop(['meanIAT', 'nIAT', 'seIAT', 'meanExp', 'nExp', 'seExp', 'refCountry', 'refNum'], axis = 1)\n",
    "referee_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_group_player = list(referee_info_df.groupby('playerShort'))\n",
    "dummydf['player'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "sum_func = lambda x, y: x+y\n",
    "def accumulate(series):\n",
    "    return reduce(sum_func, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_columns = ['games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_player_data = []\n",
    "for player_name, data in by_group_player:\n",
    "    unique_player_data.append((player_name, {column : accumulate(data[column].tolist()) for column in acc_columns}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(unique_player_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_player_data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ADA]",
   "language": "python",
   "name": "Python [ADA]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
