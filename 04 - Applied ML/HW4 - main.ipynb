{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Homework 04 - Applied ML</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join('data','CrowdstormingDataJuly1st.csv') \n",
    "df = pd.read_csv(filename)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of dyads (rows in dataframe): ', len(df))\n",
    "print('Total number of interactions between a referee and a player (nb of games): ', sum(df.games))\n",
    "print('Mean number of games for a dyad: ', np.mean(df['games']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning / setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows in dataframe: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removing raters</b>: We decided to remove row where the two rates were significantly different or if any of the rates were absent (Nan value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleandf = df.copy()\n",
    "\n",
    "## Removing null values in raters\n",
    "cleandf = cleandf[cleandf[\"rater1\"].notnull() & cleandf[\"rater2\"].notnull()]\n",
    "\n",
    "## Removing all rows where the difference between the two raters is larger than 0.25\n",
    "cleandf['difference'] = abs(cleandf.rater1 - cleandf.rater2)\n",
    "cleandf = cleandf[cleandf['difference'] <= 0.25]\n",
    "cleandf.drop('difference', axis =1, inplace=True)\n",
    "\n",
    "print(\"Number of rows in the cleaned dataframe: \", len(cleandf))\n",
    "print(\"Number of rows removed: \", (len(df)-len(cleandf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Skin tone</b>: Then we decide to take the skin tone as the mean between the two raters. This is the value that will be predicted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleandf[\"meanSkinTone\"] = abs(cleandf[\"rater1\"] - cleandf[\"rater2\"] ) / 2\n",
    "# cols = cleandf.columns.tolist()\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "# cleandf = cleandf[cols]\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Birthday date</b>: As the classifier can not understand date, we decided to change birthday date in seconds. It seemed important for us to keep the birthday date, as it could help predict the color skin if there were more people from a certain demography that played during some years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def time_to_seconds(t):\n",
    "    seconds = (pd.to_datetime(t) - datetime.datetime(1970, 1,1)).total_seconds()\n",
    "    return int(seconds)\n",
    "\n",
    "cleandf.birthday = cleandf.birthday.apply(time_to_seconds)\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dummy variables</b>: We noticed that a lot of the columns could not be used in the Random forest as they are non-numerical. As most of these features can be seen as categorical variables, we decided to make dummy variables with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The number of different positions is\", cleandf[\"position\"].unique().size)\n",
    "print(\"The number of different clubs is\",cleandf[\"club\"].unique().size)\n",
    "print(\"The number of different league countries is\",cleandf[\"leagueCountry\"].unique().size)\n",
    "print(\"The number of different referee countries is\",cleandf[\"Alpha_3\"].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of these datas, we decided to remove the \"referee country\" (Alpha_3) and to make dummy variables with the 3 other categories. We decided to remove the referee country because there were a lot of them and it seemed it would induce more error and overfitting to our classifier than it would help it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummydf = pd.get_dummies(cleandf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"position\"], sparse=False, drop_first=False)\n",
    "dummydf = pd.get_dummies(dummydf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"club\"], sparse=False, drop_first=False)\n",
    "dummydf = pd.get_dummies(dummydf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"leagueCountry\"], sparse=False, drop_first=False)\n",
    "dummydf.drop(\"Alpha_3\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of columns in the previous dataframe: \",cleandf.columns.size)\n",
    "print(\"Number of columns in the new dataframe with dummy variables: \",dummydf.columns.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Replacing Nan</b>: We realize that the dataframe still have some NaN values. We decided to substitute every NaN with the mean of their column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummydf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each column, if there is any NaN value, we compute the mean and replace the NaN values with it.\n",
    "for i in range(len(dummydf.columns)):\n",
    "    if (dummydf[dummydf.columns[i]].isnull().values.any()):\n",
    "        mean = np.mean(dummydf[dummydf.columns[i]])\n",
    "        dummydf[dummydf.columns[i]].fillna(mean, inplace = True)\n",
    "        \n",
    "dummydf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removing useless columns</b>: For the classifier, there are some columns that it makes no sense to use. These columns are the player name (and short name), the photo and the initial ratings (of rater 1 and 2). Therefore we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usedf = dummydf.drop(['playerShort', 'player', 'photoID', 'rater1', 'rater2']  , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usedf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show how we classify the data using random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def executingRandomForest(X, y, Xpd):\n",
    "    # Creating kfolds\n",
    "    once = False\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    #Iterating for kfold validation\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"TRAIN:\", train_index.size, \"TEST:\", test_index.size)\n",
    "\n",
    "        ## Making indices\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #Make classifier\n",
    "        rf = RandomForestClassifier(n_jobs = 4)\n",
    "\n",
    "        #Train the classifier\n",
    "        clf = rf.fit(X_train, y_train)\n",
    "\n",
    "        # Make prediction for testing data with the classifier\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        #Computing error\n",
    "        rf_train_score = metrics.accuracy_score(y_train, clf.predict(X_train))\n",
    "        rf_test_score = metrics.accuracy_score(y_test, y_pred)\n",
    "        print('   Training score: {:.5f}'.format(rf_train_score))\n",
    "        print('   Testing score: {:.5f}'.format(rf_test_score))\n",
    "\n",
    "\n",
    "        # Features importance score\n",
    "        if(once != True):\n",
    "            once = True\n",
    "            importances = rf.feature_importances_\n",
    "            std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                         axis=0)\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "               color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), importances[indices])\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking (first 20):\")\n",
    "    for f in range(20):\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, Xpd.columns[f], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making X (the features to use in the classifier) and Y (the value to predict). Executing the random forest algorithm on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMatrixForClassifier(df):\n",
    "    y = np.asarray(df[\"meanSkinTone\"].values, dtype=\"|S6\")\n",
    "    Xpd = df.drop(\"meanSkinTone\", axis = 1)\n",
    "    X = Xpd.as_matrix()\n",
    "    return (X, y, Xpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X, y, Xpd) = makeMatrixForClassifier(usedf)\n",
    "executingRandomForest(X, y, Xpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that we overfit greatly. Ploting the features importance show...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notOverfittingMaybedf = usedf.drop(['birthday', 'height', 'weight']  , axis=1)\n",
    "(X, y, Xpd) = makeMatrixForClassifier(notOverfittingMaybedf)\n",
    "executingRandomForest(X, y, Xpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notOverfittingMaybedf = usedf.drop(['birthday', 'height', 'weight', 'games', 'victories', 'ties', 'defeats', 'goals']  , axis=1)\n",
    "(X, y, Xpd) = makeMatrixForClassifier(notOverfittingMaybedf)\n",
    "executingRandomForest(X, y, Xpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aggregate the referee info by socker player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_columns = ['games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards']\n",
    "const_columns = ['playerShort', 'player', 'birthday', 'height', 'weight']\n",
    "majority_vote = ['club', 'leagueCountry', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_columns = ['photoID', 'refNum', 'refCountry', 'Alpha_3', 'rater1', 'rater2']\n",
    "referee_info_df = cleandf.drop(remove_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_group_player = list(referee_info_df.groupby('playerShort'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_func = lambda x, y: x+y\n",
    "def accumulate(series):\n",
    "    return reduce(sum_func, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_player_data = []\n",
    "for player_name, data in by_group_player:\n",
    "    one_occurrence = {column : data[column].tolist()[0] for column in const_columns}\n",
    "    accumulated = {column : accumulate(data[column].tolist()) for column in acc_columns}\n",
    "    #TODO: comment on: most_common()[0][0] - first 0 stands for max voted value ('name': count); \n",
    "    #                                        second 0 - gives a name from tuple \n",
    "    majority_vote = { column : Counter(data[column].tolist()).most_common()[0][0] for column in majority_vote}\n",
    "\n",
    "    #TODO: add comment\n",
    "    #################################################################################\n",
    "    acc_niat = accumulate(data['nIAT'].tolist())\n",
    "    acc_prod_iat = accumulate((data['meanIAT']*data['nIAT']).tolist())\n",
    "    \n",
    "    acc_nexp = accumulate(data['nExp'].tolist())\n",
    "    acc_prod_exp = accumulate((data['meanExp']*data['nExp']).tolist())\n",
    "    \n",
    "    #TODO: add comment\n",
    "    #################################################################################\n",
    "    acc_se_iat =accumulate((data['nIAT']).tolist())\n",
    "    acc_prod_se_iat = accumulate((data['seIAT']*data['seIAT']*data['nIAT']).tolist())\n",
    "    \n",
    "    acc_se_exp =accumulate((data['nExp']).tolist())\n",
    "    acc_prod_se_exp = accumulate((data['seExp']*data['seExp']*data['nExp']).tolist())\n",
    "    \n",
    "    wm = {'weighted_mean_iat' : acc_prod_iat/acc_niat,\n",
    "          'weighted_mean_exp' : acc_prod_exp/acc_nexp,\n",
    "          'sqrt_weighted_mean_iat' : math.sqrt(acc_prod_se_iat/acc_se_iat),\n",
    "          'sqrt_weighted_mean_exp' : math.sqrt(acc_prod_se_iat/acc_se_iat)}\n",
    "    \n",
    "    unique_player_data.append(\n",
    "        dict(list(one_occurrence.items()) +\n",
    "             list(accumulated.items()) +\n",
    "             list(majority_vote.items()) +\n",
    "             list(wm.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_df = pd.DataFrame(unique_player_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthday</th>\n",
       "      <th>club</th>\n",
       "      <th>defeats</th>\n",
       "      <th>games</th>\n",
       "      <th>goals</th>\n",
       "      <th>height</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>player</th>\n",
       "      <th>playerShort</th>\n",
       "      <th>position</th>\n",
       "      <th>redCards</th>\n",
       "      <th>sqrt_weighted_mean_exp</th>\n",
       "      <th>sqrt_weighted_mean_iat</th>\n",
       "      <th>ties</th>\n",
       "      <th>victories</th>\n",
       "      <th>weight</th>\n",
       "      <th>weighted_mean_exp</th>\n",
       "      <th>weighted_mean_iat</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303177600</td>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>228</td>\n",
       "      <td>654</td>\n",
       "      <td>9</td>\n",
       "      <td>182.0</td>\n",
       "      <td>England</td>\n",
       "      <td>Aaron Hughes</td>\n",
       "      <td>aaron-hughes</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>179</td>\n",
       "      <td>247</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.367721</td>\n",
       "      <td>0.328409</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513388800</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>122</td>\n",
       "      <td>336</td>\n",
       "      <td>62</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Aaron Hunt</td>\n",
       "      <td>aaron-hunt</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>73</td>\n",
       "      <td>141</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.441615</td>\n",
       "      <td>0.329945</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>545529600</td>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>115</td>\n",
       "      <td>412</td>\n",
       "      <td>31</td>\n",
       "      <td>165.0</td>\n",
       "      <td>England</td>\n",
       "      <td>Aaron Lennon</td>\n",
       "      <td>aaron-lennon</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>97</td>\n",
       "      <td>200</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.365628</td>\n",
       "      <td>0.328230</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>662169600</td>\n",
       "      <td>Arsenal FC</td>\n",
       "      <td>68</td>\n",
       "      <td>260</td>\n",
       "      <td>39</td>\n",
       "      <td>178.0</td>\n",
       "      <td>England</td>\n",
       "      <td>Aaron Ramsey</td>\n",
       "      <td>aaron-ramsey</td>\n",
       "      <td>Center Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.327775</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>637632000</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>43</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>France</td>\n",
       "      <td>Abdelhamid El-Kaoutari</td>\n",
       "      <td>abdelhamid-el-kaoutari</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.379497</td>\n",
       "      <td>0.338847</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    birthday               club  defeats  games  goals  height leagueCountry  \\\n",
       "0  303177600          Fulham FC      228    654      9   182.0       England   \n",
       "1  513388800      Werder Bremen      122    336     62   183.0       Germany   \n",
       "2  545529600  Tottenham Hotspur      115    412     31   165.0       England   \n",
       "3  662169600         Arsenal FC       68    260     39   178.0       England   \n",
       "4  637632000    Montpellier HSC       43    124      1   180.0        France   \n",
       "\n",
       "                   player             playerShort              position  \\\n",
       "0            Aaron Hughes            aaron-hughes           Center Back   \n",
       "1              Aaron Hunt              aaron-hunt  Attacking Midfielder   \n",
       "2            Aaron Lennon            aaron-lennon      Right Midfielder   \n",
       "3            Aaron Ramsey            aaron-ramsey     Center Midfielder   \n",
       "4  Abdelhamid El-Kaoutari  abdelhamid-el-kaoutari           Center Back   \n",
       "\n",
       "   redCards  sqrt_weighted_mean_exp  sqrt_weighted_mean_iat  ties  victories  \\\n",
       "0         0                0.000121                0.000121   179        247   \n",
       "1         1                0.000058                0.000058    73        141   \n",
       "2         0                0.000086                0.000086    97        200   \n",
       "3         1                0.000218                0.000218    42        150   \n",
       "4         2                0.000478                0.000478    40         41   \n",
       "\n",
       "   weight  weighted_mean_exp  weighted_mean_iat  yellowCards  yellowReds  \n",
       "0    71.0           0.367721           0.328409           19           0  \n",
       "1    73.0           0.441615           0.329945           42           0  \n",
       "2    63.0           0.365628           0.328230           11           0  \n",
       "3    76.0           0.412859           0.327775           31           0  \n",
       "4    73.0           0.379497           0.338847            8           4  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
