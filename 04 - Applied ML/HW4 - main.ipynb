{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Homework 04 - Applied ML</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation of the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join('data','CrowdstormingDataJuly1st.csv') \n",
    "df = pd.read_csv(filename)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of dyads (rows in dataframe): ', len(df))\n",
    "print('Total number of interactions between a referee and a player (nb of games): ', sum(df.games))\n",
    "print('Mean number of games for a dyad: ', np.mean(df['games']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning / setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows in dataframe: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Removing raters</b>: We decided to remove row where the two rates were significantly different or if any of the rates were absent (Nan value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleandf = df.copy()\n",
    "\n",
    "## Removing null values in raters\n",
    "cleandf = cleandf[cleandf[\"rater1\"].notnull() & cleandf[\"rater2\"].notnull()]\n",
    "\n",
    "## Removing all rows where the difference between the two raters is larger than 0.25\n",
    "cleandf['difference'] = abs(cleandf.rater1 - cleandf.rater2)\n",
    "cleandf = cleandf[cleandf['difference'] <= 0.25]\n",
    "cleandf.drop('difference', axis =1, inplace=True)\n",
    "\n",
    "print(\"Number of rows in the cleaned dataframe: \", len(cleandf))\n",
    "print(\"Number of rows removed: \", (len(df)-len(cleandf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Skin tone</b>: Then we decide to take the skin tone as the mean between the two raters. This is the value that will be predicted later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleandf[\"meanSkinTone\"] = abs(cleandf[\"rater1\"] - cleandf[\"rater2\"] ) / 2\n",
    "# cols = cleandf.columns.tolist()\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "# cleandf = cleandf[cols]\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Birthday date</b>: As the classifier can not understand date, we decided to change birthday date in seconds. It seemed important for us to keep the birthday date, as it could help predict the color skin if there were more people from a certain demography that played during some years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def time_to_seconds(t):\n",
    "    seconds = (pd.to_datetime(t) - datetime.datetime(1970, 1,1)).total_seconds()\n",
    "    return int(seconds)\n",
    "\n",
    "cleandf.birthday = cleandf.birthday.apply(time_to_seconds)\n",
    "cleandf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dummy variables</b>: We noticed that a lot of the columns could not be used in the Random forest as they are non-numerical. As most of these features can be seen as categorical variables, we decided to make dummy variables with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The number of different positions is\", cleandf[\"position\"].unique().size)\n",
    "print(\"The number of different clubs is\",cleandf[\"club\"].unique().size)\n",
    "print(\"The number of different league countries is\",cleandf[\"leagueCountry\"].unique().size)\n",
    "print(\"The number of different referee countries is\",cleandf[\"Alpha_3\"].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of these datas, we decided to remove the \"referee country\" (Alpha_3) and to make dummy variables with the 3 other categories. We decided to remove the referee country because there were a lot of them and it seemed it would induce more error and overfitting to our classifier than it would help it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummydf = pd.get_dummies(cleandf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"position\"], sparse=False, drop_first=False)\n",
    "dummydf = pd.get_dummies(dummydf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"club\"], sparse=False, drop_first=False)\n",
    "dummydf = pd.get_dummies(dummydf, prefix=None, prefix_sep='_', dummy_na=False, columns=[\"leagueCountry\"], sparse=False, drop_first=False)\n",
    "dummydf.drop(\"Alpha_3\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of columns in the previous dataframe: \",cleandf.columns.size)\n",
    "print(\"Number of columns in the new dataframe with dummy variables: \",dummydf.columns.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<b>Removing useless columns</b>: For the classifier, there are some columns that it makes no sense to use. These columns are the player name (and short name), the photo and the initial ratings (of rater 1 and 2). Therefore we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "usedf = dummydf.drop(['playerShort', 'player', 'photoID', 'rater1', 'rater2']  , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Replacing Nan</b>: We realize that the dataframe still have some NaN values. We decided to substitute every NaN with the mean of their column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usedf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each column, if there is any NaN value, we compute the mean and replace the NaN values with it.\n",
    "for i in range(len(usedf.columns)):\n",
    "    if (usedf[usedf.columns[i]].isnull().values.any()):\n",
    "        mean = np.mean(usedf[usedf.columns[i]])\n",
    "        usedf[usedf.columns[i]].fillna(mean, inplace = True)\n",
    "        \n",
    "usedf.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usedf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will show how we classify the data using random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = len(y)\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import linear_model, metrics\n",
    "from  sklearn.metrics import log_loss\n",
    "\n",
    "sum_feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "def cross_validation(y, x, k_indices, k):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    print(\"kkkkkkkk\", k)\n",
    "    te_indice = k_indices[k]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    \n",
    "    y_te = y[te_indice]\n",
    "    y_tr = y[tr_indice]\n",
    "    x_te = x[te_indice]\n",
    "    x_tr = x[tr_indice]\n",
    "    \n",
    "    #Make classifier\n",
    "    rf = RandomForestClassifier(n_jobs = 4)\n",
    "\n",
    "    #Train the classifier\n",
    "    clf = rf.fit(x_tr, y_tr)\n",
    "    path = rf.feature_importances_\n",
    "    global sum_feature_importances\n",
    "    sum_feature_importances = np.add(sum_feature_importances, path)\n",
    "\n",
    "    # Make prediction for testing data with the classifier\n",
    "    y_pred = clf.predict(x_te)\n",
    "\n",
    "    #Compute error (trying with 2 different methods)\n",
    "    #rf_score1 = log_loss(y_te, y_pred)\n",
    "    rf_score2 = metrics.accuracy_score(y_te, y_pred)\n",
    "    \n",
    "    print(y_pred)\n",
    "\n",
    "    #print('score: ', rf_score1)\n",
    "    print('score 2: ', rf_score2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making X (the features to use in the classifier) and Y (the value to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.asarray(usedf[\"meanSkinTone\"].values, dtype=\"|S6\")\n",
    "subDummydf = usedf.drop(\"meanSkinTone\", axis = 1)\n",
    "X = subDummydf.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the K_fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_fold = 8\n",
    "k_indices = build_k_indices(Y, k_fold, 1)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    cross_validation(Y, X, k_indices, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_feature_importances / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_feature_importances.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ADA]",
   "language": "python",
   "name": "Python [ADA]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
